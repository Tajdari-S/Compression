{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ+9iTy6YmlfLDy3sbHNy9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tajdari-S/Compression/blob/main/SPMLF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUk-O7IEnOGZ",
        "outputId": "6234b67b-a39a-4d78-cedc-356c4e0fa016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary sparse matrix data saved to output_binary_sparse.npz\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix, save_npz\n",
        "\n",
        "def convert_to_binary(entry):\n",
        "    binary_data = []\n",
        "\n",
        "    for key, value in entry.items():\n",
        "        if isinstance(value, str):\n",
        "            # Convert string to binary using UTF-8 encoding\n",
        "            binary_data.append(value.encode('utf-8'))\n",
        "        elif isinstance(value, list):\n",
        "            # Convert numerical values to numpy array and then to binary\n",
        "            binary_data.append(np.array(value).tobytes())\n",
        "        else:\n",
        "            binary_data.append(value)\n",
        "\n",
        "    return binary_data\n",
        "\n",
        "# Specify the input and output file paths\n",
        "input_file_path = \"input_data.json\"\n",
        "output_file_path = \"output_binary_sparse.npz\"\n",
        "\n",
        "# Load JSON data from the input file\n",
        "with open(input_file_path, 'r') as file:\n",
        "    input_data = json.load(file)\n",
        "\n",
        "# Convert each entry to binary data\n",
        "binary_data = [convert_to_binary(entry) for entry in input_data]\n",
        "\n",
        "# Create a sparse matrix from binary data using coo_matrix\n",
        "binary_matrix = coo_matrix(binary_data)\n",
        "\n",
        "# Save the binary sparse matrix\n",
        "save_npz(output_file_path, binary_matrix)\n",
        "\n",
        "print(\"Binary sparse matrix data saved to\", output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from scipy.sparse import load_npz\n",
        "\n",
        "def convert_from_binary(binary_data):\n",
        "    entry = {}\n",
        "    index = 0\n",
        "\n",
        "    for key, value in original_data[0].items():\n",
        "        if isinstance(value, str):\n",
        "            # Decode binary data to string using UTF-8 encoding\n",
        "            entry[key] = binary_data[index].decode('utf-8')\n",
        "        elif isinstance(value, list):\n",
        "            # Convert binary data to numpy array\n",
        "            array_size = len(value)\n",
        "            array_bytes = binary_data[index][:array_size * 8]\n",
        "            entry[key] = np.frombuffer(array_bytes, dtype=np.float64).tolist()\n",
        "            index += 1\n",
        "        else:\n",
        "            entry[key] = binary_data[index]\n",
        "\n",
        "        index += 1\n",
        "\n",
        "    return entry\n",
        "\n",
        "# Specify the input and output file paths\n",
        "input_file_path = \"input_data.json\"\n",
        "output_file_path = \"output_binary_sparse.npz\"\n",
        "\n",
        "# Load original JSON data for reference\n",
        "with open(input_file_path, 'r') as file:\n",
        "    original_data = json.load(file)\n",
        "\n",
        "# Load the binary sparse matrix\n",
        "binary_matrix = load_npz(output_file_path)\n",
        "\n",
        "# Convert binary matrix to list of binary entries\n",
        "binary_data_list = binary_matrix.data.tolist()\n",
        "\n",
        "# Convert each binary entry to the original format\n",
        "original_entries = [convert_from_binary(binary_data_list[i:i+len(original_data[0])]) for i in range(0, len(binary_data_list), len(original_data[0]))]\n",
        "\n",
        "# Save the reconstructed JSON file\n",
        "output_json_path = \"reconstructed_data.json\"\n",
        "with open(output_json_path, 'w') as output_file:\n",
        "    json.dump(original_entries, output_file, indent=2)\n",
        "\n",
        "print(\"Reconstructed JSON data saved to\", output_json_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRldacyyPPxQ",
        "outputId": "dafe21a6-76b7-4631-fce7-4e5b0959c068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed JSON data saved to reconstructed_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from scipy.sparse import load_npz, save_npz\n",
        "\n",
        "def convert_from_binary(binary_data):\n",
        "    entry = {}\n",
        "    index = 0\n",
        "\n",
        "    for key, value in original_data[0].items():\n",
        "        if isinstance(value, str):\n",
        "            # Decode binary data to string using UTF-8 encoding\n",
        "            entry[key] = binary_data[index].decode('utf-8')\n",
        "        elif isinstance(value, list):\n",
        "            # Convert binary data to numpy array\n",
        "            array_size = len(value)\n",
        "            array_bytes = binary_data[index][:array_size * 8]\n",
        "            entry[key] = np.frombuffer(array_bytes, dtype=np.float64).tolist()\n",
        "            index += 1\n",
        "        else:\n",
        "            entry[key] = binary_data[index]\n",
        "\n",
        "        index += 1\n",
        "\n",
        "    return entry\n",
        "\n",
        "# Specify the input and output file paths\n",
        "input_file_path = \"input_data.json\"\n",
        "output_file_path = \"output_binary_sparse.npz\"\n",
        "\n",
        "# Load original JSON data for reference\n",
        "with open(input_file_path, 'r') as file:\n",
        "    original_data = json.load(file)\n",
        "\n",
        "# Load the binary sparse matrix\n",
        "binary_matrix = load_npz(output_file_path)\n",
        "\n",
        "# Convert binary matrix to list of binary entries\n",
        "binary_data_list = binary_matrix.data.tolist()\n",
        "\n",
        "# Convert each binary entry to the original format\n",
        "original_entries = [convert_from_binary(binary_data_list[i:i+len(original_data[0])]) for i in range(0, len(binary_data_list), len(original_data[0]))]\n",
        "\n",
        "# Save the reconstructed JSON file\n",
        "output_json_path = \"reconstructed_data.json\"\n",
        "with open(output_json_path, 'w') as output_file:\n",
        "    json.dump(original_entries, output_file, indent=2)\n",
        "\n",
        "# Save the binary sparse matrix in a compressed format\n",
        "save_npz(\"compressed_output_binary_sparse.npz\", binary_matrix)\n",
        "\n",
        "print(\"Reconstructed JSON data saved to\", output_json_path)\n",
        "print(\"Compressed binary sparse matrix saved to compressed_output_binary_sparse.npz\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsOVDDu6aMwM",
        "outputId": "5385b57f-e845-4569-8b3a-e9c9f0f3ea8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed JSON data saved to reconstructed_data.json\n",
            "Compressed binary sparse matrix saved to compressed_output_binary_sparse.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix, save_npz, load_npz\n",
        "import gzip\n",
        "\n",
        "def convert_to_binary(entry):\n",
        "    binary_data = []\n",
        "    for key, value in entry.items():\n",
        "        if isinstance(value, str):\n",
        "            # Encode string to binary data using UTF-8 encoding\n",
        "            encoded_value = value.encode('utf-8')\n",
        "            binary_data.append(encoded_value)\n",
        "        elif isinstance(value, list):\n",
        "            # Convert list to numpy array and then to binary data\n",
        "            array_bytes = np.array(value, dtype=np.float64).tobytes()\n",
        "            binary_data.append(array_bytes)\n",
        "        else:\n",
        "            binary_data.append(value)\n",
        "\n",
        "    return binary_data\n",
        "\n",
        "def compress_and_save_sparse_matrix(matrix, output_file_path):\n",
        "    # Save the sparse matrix to a binary file\n",
        "    save_npz(output_file_path, matrix)\n",
        "\n",
        "    # Open the binary file and compress it using gzip\n",
        "    with open(output_file_path, 'rb') as binary_file:\n",
        "        with gzip.open(output_file_path + '.gz', 'wb') as compressed_file:\n",
        "            compressed_file.writelines(binary_file)\n",
        "\n",
        "def load_and_decompress_sparse_matrix(input_file_path):\n",
        "    # Open the compressed file and decompress it using gzip\n",
        "    with gzip.open(input_file_path, 'rb') as compressed_file:\n",
        "        with open(input_file_path.replace('.gz', '_decompressed.npz'), 'wb') as binary_file:\n",
        "            binary_file.writelines(compressed_file)\n",
        "\n",
        "    # Load the sparse matrix from the decompressed binary file\n",
        "    decompressed_matrix = load_npz(input_file_path.replace('.gz', '_decompressed.npz'))\n",
        "    return decompressed_matrix\n",
        "\n",
        "# Specify the input and output file paths\n",
        "input_file_path = \"input_data.json\"\n",
        "output_file_path = \"output_sparse_matrix.npz\"\n",
        "\n",
        "# Load original JSON data\n",
        "with open(input_file_path, 'r') as file:\n",
        "    original_data = json.load(file)\n",
        "\n",
        "# Convert each entry to binary format\n",
        "binary_entries = [convert_to_binary(entry) for entry in original_data]\n",
        "\n",
        "# Ensure consistent data types for the binary entries\n",
        "binary_data_list = [item if isinstance(item, (bytes, int, float)) else item[0] for item in binary_entries]\n",
        "\n",
        "# Create a binary sparse matrix using COO format\n",
        "num_entries = len(original_data)\n",
        "num_features = len(binary_data_list) // num_entries\n",
        "rows = [i // num_features for i in range(len(binary_data_list))]\n",
        "cols = [i % num_features for i in range(len(binary_data_list))]\n",
        "binary_matrix = coo_matrix((binary_data_list, (rows, cols)))\n",
        "\n",
        "# Compress and save the sparse matrix\n",
        "compress_and_save_sparse_matrix(binary_matrix, output_file_path)\n",
        "\n",
        "# Load and decompress the sparse matrix\n",
        "decompressed_matrix = load_and_decompress_sparse_matrix(output_file_path + '.gz')\n",
        "\n",
        "# Optional: Verify that the loaded matrix matches the original matrix\n",
        "assert np.array_equal(binary_matrix.data, decompressed_matrix.data)\n",
        "assert np.array_equal(binary_matrix.row, decompressed_matrix.row)\n",
        "assert np.array_equal(binary_matrix.col, decompressed_matrix.col)\n",
        "\n",
        "print(\"Compression and reconstruction completed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e6Zq3FYe4-r",
        "outputId": "073f6cd7-57b3-4f84-8525-968957d2e7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compression and reconstruction completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report on the Compressed Binary Sparse Matrix Generation and Reconstruction Code\n",
        "\n",
        "Objective:\n",
        "The objective of the provided code is to convert data from a JSON file into a compressed binary sparse matrix, store it, and then reconstruct the matrix from the stored compressed format.\n",
        "\n",
        "Overview of the Code:\n",
        "\n",
        "Data Conversion to Binary Format:\n",
        "\n",
        "The original JSON data is loaded from a specified file (input_file_path) into the variable original_data.\n",
        "The function convert_to_binary is employed to convert each entry in original_data to binary format. The function ensures appropriate encoding for strings and converts lists to binary using NumPy.\n",
        "Sparse Matrix Construction:\n",
        "\n",
        "The binary entries are then used to construct a binary sparse matrix using the COO (Coordinate) format. The COO format is chosen for its flexibility in handling different data types, including strings.\n",
        "The COO matrix is created with the help of the coo_matrix function from the scipy.sparse library.\n",
        "Compression and Storage:\n",
        "\n",
        "The binary sparse matrix is saved to a file (output_file_path) using save_npz.\n",
        "The saved binary file is then compressed using the gzip library to reduce the file size. The compressed file is saved with a \".gz\" extension.\n",
        "Reconstruction from Compressed Format:\n",
        "\n",
        "The compressed binary file is loaded and decompressed using gzip.\n",
        "The decompressed binary data is then loaded into a sparse matrix using the load_npz function.\n",
        "Verification:\n",
        "\n",
        "Optional verification steps are included to ensure the integrity of the reconstructed matrix. These steps compare the data, row indices, and column indices of the original and decompressed matrices.\n",
        "Results and Output:\n",
        "\n",
        "If the code runs successfully, it prints a message indicating the completion of compression and reconstruction.\n",
        "Considerations and Adjustments:\n",
        "\n",
        "The convert_to_binary function ensures that string data is encoded in UTF-8 and truncates long strings. The truncation length can be adjusted based on the characteristics of the data.\n",
        "The COO format is chosen for its flexibility with various data types, but other sparse matrix formats can be considered based on specific requirements.\n",
        "Conclusion:\n",
        "The code successfully achieves the goal of converting JSON data into a compressed binary sparse matrix, storing it, and reconstructing the matrix from the compressed format. The use of gzip compression contributes to efficient storage, especially in scenarios where the data matrix is sparse with many zero entries. The flexibility of the COO format allows the code to handle diverse data types, including strings, during the conversion and reconstruction processes. The optional verification steps enhance the reliability of the code.\n",
        "\n",
        "Recommendations for Future Work:\n",
        "\n",
        "Depending on the specific characteristics of the data, further optimizations and adjustments can be explored to enhance compression ratios.\n",
        "Consideration of alternative sparse matrix formats based on the nature of the data could be investigated.\n",
        "In a real-world scenario, additional error handling and logging mechanisms may be implemented to enhance robustness."
      ],
      "metadata": {
        "id": "adzASzJ8goWr"
      }
    }
  ]
}